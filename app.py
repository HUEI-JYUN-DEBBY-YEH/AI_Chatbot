from flask import Flask, request, render_template, session, redirect, url_for, jsonify
from flask_sqlalchemy import SQLAlchemy
import os
import faiss
import numpy as np
import openai
from sentence_transformers import SentenceTransformer
from datetime import datetime
from dotenv import load_dotenv
import pickle

app = Flask(__name__, template_folder='template')
app.secret_key = 'asdfghjkl0987654321'  # è¨­å®š session å®‰å…¨å¯†é‘°

# æ¨¡æ“¬èº«åˆ†é©—è­‰è³‡æ–™åº«
users = {
    "David Chou": "A123456789",
    "Vivian Kuo": "B223348910",
    "Angela Tsai": "C221159139"
}

# è¨­å®šè³‡æ–™åº«ï¼ˆRender æä¾›çš„ PostgreSQL æˆ–æœ¬åœ° SQLiteï¼‰
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///test.db")
app.config["SQLALCHEMY_DATABASE_URI"] = DATABASE_URL
app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False
db = SQLAlchemy(app)

# âœ… è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()

# âœ… è®€å– OpenAI API Key
openai.api_key = os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    raise ValueError("âŒ ç¼ºå°‘ OPENAI_API_KEYï¼Œè«‹ç¢ºèª Render ç’°å¢ƒè®Šæ•¸è¨­å®šï¼")

# âœ… è®€å–ç’°å¢ƒè®Šæ•¸
FAISS_DB_PATH = os.getenv("FAISS_DB_PATH", "/opt/render/project/src/Output_Vector")
TEXT_DATA_PATH = os.getenv("TEXT_DATA_PATH", "/opt/render/project/src/Output_Clean")
FAISS_INDEX_FILE = os.path.join(FAISS_DB_PATH, "vector_database.faiss")
PICKLE_FILE = os.path.join(FAISS_DB_PATH, "documents.pkl")

# âœ… ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
os.makedirs(FAISS_DB_PATH, exist_ok=True)

# è®€å– Hugging Face Token
hf_token = os.getenv("HUGGINGFACE_TOKEN")

# è¨­å®š cache folder ä¸¦ä¸‹è¼‰æ¨¡å‹
embedding_model = SentenceTransformer(
    "sentence-transformers/all-MiniLM-L6-V2", 
    cache_folder="./model_cache", 
    use_auth_token=hf_token  # ä½¿ç”¨ Hugging Face Token
)

# âœ… è®€å–æ–‡æœ¬ä¸¦å»ºç«‹å‘é‡ç´¢å¼•
documents = []
document_vectors = []

if os.path.exists(TEXT_DATA_PATH):
    txt_files = sorted([f for f in os.listdir(TEXT_DATA_PATH) if f.endswith(".txt")])[:100]

    for filename in txt_files:
        file_path = os.path.join(TEXT_DATA_PATH, filename)
        with open(file_path, "r", encoding="utf-8") as f:
            text_content = f.read().strip()
            documents.append(text_content)
            document_vectors.append(embedding_model.encode(text_content))

# âœ… ç¢ºä¿ `document_vectors` åœ¨ FAISS åˆå§‹åŒ–å‰å·²ç¶“æœ‰è³‡æ–™
if documents and document_vectors:
    #FAISSåˆå§‹åŒ–
    d = 384  # å‘é‡ç¶­åº¦
    nlist = max(1, len(document_vectors) // 40)  # è®“ centroids æ•¸é‡é©æ‡‰ä½ çš„æ•¸æ“š
    quantizer = faiss.IndexFlatL2(d)  # é‡åŒ–å™¨
    index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)
    
    index.train(np.array(document_vectors).astype(np.float32))  # âœ… é€™è£¡æ‰åŸ·è¡Œè¨“ç·´
    index.add(np.array(document_vectors).astype(np.float32))  # âœ… é€™è£¡æ–°å¢è³‡æ–™
    faiss.write_index(index, FAISS_INDEX_FILE)  # âœ… å¯«å…¥ç´¢å¼•
    
    # âœ… **å„²å­˜ `documents` ä»¥ä¾¿æœªä¾†æŸ¥æ‰¾å°æ‡‰æ–‡æœ¬**
    with open(PICKLE_FILE, "wb") as f:
        pickle.dump(documents, f)

    print("âœ… FAISS è³‡æ–™åº«å·²å»ºç«‹ä¸¦å„²å­˜ï¼")
    print(f"ğŸ“ Documents é•·åº¦: {len(documents)}")
else:
    print("âŒ éŒ¯èª¤ï¼šç„¡æ³•å»ºç«‹ FAISSï¼Œå› ç‚º `document_vectors` ç‚ºç©ºï¼")


# âœ… è®€å– FAISS è³‡æ–™åº«
try:
    index = faiss.read_index(FAISS_INDEX_FILE)

    # âœ… è®€å– `documents`
    if os.path.exists(PICKLE_FILE):
        with open(PICKLE_FILE, "rb") as f:
            documents = pickle.load(f)
    
    print("âœ… FAISS è³‡æ–™åº«æˆåŠŸè¼‰å…¥ï¼")
    print(f"ğŸ“ Documents é•·åº¦: {len(documents)}")
    print(f"ğŸ“‚ Documents é•·åº¦: {len(documents)}, å‘é‡æ•¸é‡: {len(document_vectors)}")
except Exception as e:
    print(f"âŒ FAISS è¼‰å…¥å¤±æ•—: {e}")

# âœ… å®šç¾© embedding å‡½æ•¸
def embed_text(text):
    return np.array([embedding_model.encode(text)]).astype(np.float32)

# âœ… è®“ä½¿ç”¨è€…é©—è­‰æ‰èƒ½é€²å…¥èŠå¤©
@app.route("/")
def home():
    if "username" not in session:
        return redirect(url_for("verification"))
    return redirect(url_for("mainpage"))

@app.route("/verification", methods=["GET", "POST"])
def verification():
    if request.method == "POST":
        username = request.form.get("username")
        password = request.form.get("password")

        if users.get(username) == password:
            session["username"] = username  # è¨­å®š session
            return redirect(url_for("mainpage"))
        else:
            return render_template("verification.html", error="å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤ï¼Œè«‹é‡æ–°è¼¸å…¥ï¼")

    return render_template("verification.html")  # é¡¯ç¤ºç™»å…¥ç•«é¢

@app.route("/mainpage")
def mainpage():
    if "username" not in session:
        return redirect(url_for("verification"))
    return render_template("chatbot_mainpage.html")

# âœ… èŠå¤©åŠŸèƒ½
@app.route("/api/chat", methods=["POST"])
def chat():
    if "username" not in session:
        return jsonify({"error": "è«‹å…ˆç™»å…¥"}), 401

    try:
        data = request.get_json()
        user_input = data.get("message", "")
        print(f"ä½¿ç”¨è€…è¼¸å…¥: {user_input}")

        if not user_input:
            return jsonify({"response": "è«‹è¼¸å…¥æœ‰æ•ˆçš„å•é¡Œ"}), 400

        print("ğŸ” æ¸¬è©¦ FAISS æª¢ç´¢...")
        user_embedding = embed_text(user_input)
        distances, indices = index.search(user_embedding, k=3)
        print("âœ… FAISS æ¸¬è©¦æˆåŠŸ")
        print(f"ğŸ“Œ FAISS æœå°‹çµæœ - è·é›¢: {distances}, ç´¢å¼•: {indices}")

        retrieved_texts = []
        for idx in indices[0]:
            if 0 <= idx < len(documents):
                text = documents[idx][:300]  # âœ… é™åˆ¶æ¯å€‹æ–‡æœ¬æœ€å¤š 300 å­—
                retrieved_texts.append(text)
            else:
                retrieved_texts.append(f"æœªçŸ¥å…§å®¹ (ç´¢å¼• {idx})")

        print(f"ğŸ” FAISS æœç´¢çµæœï¼š{retrieved_texts}")

        if all("æœªçŸ¥å…§å®¹" in text for text in retrieved_texts):
            return jsonify({"error": "âŒ FAISS æœç´¢ç„¡æ•ˆï¼Œè«‹ç¢ºèªç´¢å¼•åº«å…§å®¹"}), 500

        print("ğŸ“ å‘¼å« OpenAI API ä¸­...")
        prompt = f"""
        ä½ æ˜¯ä¸€å€‹ AI åŠ©æ‰‹ï¼Œè«‹æ ¹æ“š FAISS æä¾›çš„èƒŒæ™¯è³‡è¨Šå›ç­”å•é¡Œã€‚
        èƒŒæ™¯è³‡æ–™ï¼š{retrieved_texts}
        å•é¡Œï¼š{user_input}
        """
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": "è«‹æä¾›å›ç­”"},
            ],
            temperature=0,
            max_tokens=150,
            stop=["\n\n"]  # âœ… è®“å›æ‡‰åœ¨é›™æ›è¡Œæ™‚çµæŸ
        )

        answer = response.choices[0].message.content
        print(f"ğŸ’¬ OpenAI å›æ‡‰: {answer}")

        # âœ… å„²å­˜å°è©±åˆ°è³‡æ–™åº«
        chat_record = ChatHistory(
            username=session["username"],
            user_message=user_input,
            bot_response=answer
        )
        db.session.add(chat_record)
        db.session.commit()

        return jsonify({"response": answer})

    except Exception as e:
        print(f"âŒ FAISS æ¸¬è©¦å¤±æ•—: {e}")
        return jsonify({"error": "ä¼ºæœå™¨éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"}), 500

# âœ… å°è©±æ­·å²ç´€éŒ„
@app.route("/api/history", methods=["GET"])
def history():
    if "username" not in session:
        return jsonify({"error": "è«‹å…ˆç™»å…¥"}), 401

    records = ChatHistory.query.filter_by(username=session["username"]).all()
    return jsonify([
        {"user_message": r.user_message, "bot_response": r.bot_response, "timestamp": r.timestamp}
        for r in records
    ])

# âœ… è¨­å®š ChatHistory è³‡æ–™è¡¨
class ChatHistory(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(100), nullable=False)
    user_message = db.Column(db.Text, nullable=False)
    bot_response = db.Column(db.Text, nullable=False)
    timestamp = db.Column(db.DateTime, default=datetime.utcnow)

with app.app_context():
    db.create_all()

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))  # Render æœƒè‡ªå‹•æä¾› PORT
    app.run(host="0.0.0.0", port=port, debug=True)
