
from flask import Flask, request, render_template, session, redirect, url_for, jsonify
import os, json, torch
import openai
from dotenv import load_dotenv
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sentence_transformers import SentenceTransformer
from datetime import datetime

# === ç’°å¢ƒè®Šæ•¸èˆ‡ OpenAI Key ===
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

app = Flask(__name__, template_folder='template')
app.secret_key = 'secure_key'

# ä½¿ç”¨è€…å¸³å¯†ï¼ˆç°¡åŒ–æ¸¬è©¦ç”¨ï¼‰
users = {"Debby": "123456"}

# === è¼‰å…¥æ¨¡å‹èˆ‡åˆ†é¡è³‡æ–™ ===
model_name = "DEBBY-YEH/finetuned-laborlaw-bert"
bert_tokenizer = AutoTokenizer.from_pretrained(model_name)
bert_model = AutoModelForSequenceClassification.from_pretrained(model_name)

label2id = {
  "å‡åˆ¥": 0, "å…¶ä»–": 1, "å¥‘ç´„èˆ‡è˜åƒ±é—œä¿‚": 2,
  "å·¥æ™‚": 3, "çµ‚æ­¢èˆ‡è§£åƒ±": 4, "è·å ´å®‰å…¨èˆ‡æ€§åˆ¥å¹³ç­‰": 5, "è–ªè³‡": 6
}
id2label = {v: k for k, v in label2id.items()}

with open("classified_chunks_cleaned.json", "r", encoding="utf-8") as f:
    chunk_data = json.load(f)

embedding_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

def predict_category(text):
    inputs = bert_tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = bert_model(**inputs)
        predicted_id = torch.argmax(outputs.logits, dim=1).item()
        return id2label[predicted_id]

@app.route("/")
def home():
    if "username" not in session:
        return redirect(url_for("verification"))
    return redirect(url_for("mainpage"))

@app.route("/verification", methods=["GET", "POST"])
def verification():
    if request.method == "POST":
        username = request.form.get("username")
        password = request.form.get("password")
        if users.get(username) == password:
            session["username"] = username
            return redirect(url_for("mainpage"))
        else:
            return render_template("verification.html", error="å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤")
    return render_template("verification.html")

@app.route("/mainpage")
def mainpage():
    if "username" not in session:
        return redirect(url_for("verification"))
    return render_template("chatbot_mainpage.html")

@app.route("/api/chat", methods=["POST"])
def chat():
    if "username" not in session:
        return jsonify({"error": "è«‹å…ˆç™»å…¥"}), 401

    data = request.get_json()
    user_input = data.get("message", "")
    if not user_input:
        return jsonify({"response": "è«‹è¼¸å…¥å•é¡Œ"}), 400

    try:
        predicted_label = predict_category(user_input)
        chunks = chunk_data.get(predicted_label, [])[:3]

        if not chunks:
            return jsonify({"response": f"âŒ æœªæ‰¾åˆ°åˆ†é¡ {predicted_label} çš„è³‡æ–™ã€‚"})

        print(f"ğŸ“Œ BERT åˆ†é¡çµæœï¼š{predicted_label}")

        prompt = f"""
        ä½ æ˜¯ä¸€ä½ç†Ÿæ‚‰å°ç£å‹åŸºæ³•çš„æ³•å¾‹åŠ©ç†ï¼Œè«‹æ ¹æ“šä¸‹åˆ—èƒŒæ™¯è³‡æ–™å›ç­”ä½¿ç”¨è€…å•é¡Œï¼š
        èƒŒæ™¯è³‡æ–™ï¼š{chunks}
        å•é¡Œï¼š{user_input}
        """

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": "è«‹æ ¹æ“šä¸Šé¢å…§å®¹å›ç­”å•é¡Œ"},
            ],
            temperature=0,
            max_tokens=200
        )

        answer = response.choices[0].message["content"]
        return jsonify({"response": answer})

    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼š{e}")
        return jsonify({"error": "ä¼ºæœå™¨éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"}), 500

@app.route("/logout")
def logout():
    session.clear()
    return redirect(url_for("verification"))

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    print("ğŸš€ Flask æº–å‚™å•Ÿå‹•ä¸­...")
    app.run(host="0.0.0.0", port=port, debug=True)
