This project integrates a fine-tuned BERT model to classify user inquiries related to Taiwan's Labor Standards Act. Upon classification, the system retrieves predefined responses from a local dictionary, effectively simulating a legal chatbot. The architecture encompasses user input processing, BERT-based classification, and response generation.â€‹

# ðŸ¤– Taiwan Labor Law Chatbot Evaluation Report

## ðŸ“„ Project Overview
This project evaluates the performance of two chatbot backend implementations for Taiwan Labor Law question answering:

1. **GPT + FAISS baseline retrieval**
2. **Fine-tuned BERT classifier + GPT hybrid**

Evaluation was conducted on a **50-question human-labeled test set**, and the accuracy of answers was manually annotated as:
- `1` = Correct
- `0` = Incorrect

---

## ðŸŽ¯ Accuracy Comparison

| Model               | Accuracy  |
|---------------------|-----------|
| **BERT Fine-tuned** | **90%**   |
| GPT + FAISS         | **18%**   |

---

## ðŸ” Insight Analysis

### 1. BERT Fine-tune Model
- Achieved **90% accuracy**, showing strong domain adaptation.
- Handles legal intent and category prediction with high consistency.
- Ideal for intent classification and grounding future chatbot responses.

### 2. GPT + FAISS Baseline
- Only **18% accuracy**, struggling with:
  - Ambiguous or implicit phrasing
  - Legal terminology variations
- Solely relying on semantic similarity is insufficient for legal use cases.

---

## ðŸ”„ Suggested Architecture
- âœ… **Adopt BERT classifier as core routing engine**
- ðŸ”„ Combine with GPT to generate fluent answers **after classification**
- ðŸ”¢ Future improvement: explore **multi-task learning** (classification + generation)

---

## ðŸ“‹ Evaluation Dataset Summary
- **Number of questions:** 50
- **Annotation format:** CSV with columns: `question`, `answer`, `category`, `timestamp`, `label`
- **Label = 1** for correct, **0** for incorrect

---

## ðŸ“¦ Repository
- Source Code: [AI_Chatbot Repository](https://github.com/HUEI-JYUN-DEBBY-YEH/AI_Chatbot)
- BERT Training Project: [BERT Fine-tune for Labor Law](https://github.com/HUEI-JYUN-DEBBY-YEH/bert-fine-tune-taiwan-labor-law)
- Deployed Demo: [BERT Fine-tune Chatbot on Render](https://bert-fine-tune.onrender.com)

---

## ðŸš€ Conclusion
> The fine-tuned BERT classifier significantly improves legal QA accuracy and is production-ready. GPT alone is insufficient for such high-precision applications. A hybrid approach is highly recommended for future iterations.

---

## ðŸŒŸ Author
- [@HUEI-JYUN-DEBBY-YEH](https://github.com/HUEI-JYUN-DEBBY-YEH)
- NLP Application Engineer in Training
- Focus: LLM, vector search, Flask API, multimodal, chatbot deployment
