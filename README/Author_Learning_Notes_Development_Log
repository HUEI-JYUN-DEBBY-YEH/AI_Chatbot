# Learning Notes & Development Log

This document records the design process, challenges, and solutions encountered during development.  
All solutions and suggestions were provided by ChatGPT.

---

## **2025.02.28 (Friday) - Initial Design**
### **Q1: How to trigger user verification before accessing AI Chatbot?**
**Solution by ChatGPT:**
1. Use `session` for user authentication.
2. Redirect to `mainpage` upon successful verification.
3. Implement logout functionality after service usage.

---

## **2025.03.01 (Saturday) - Key Code Changes**
1. Convert all inputs and responses into **vector representations** and retrieve from `.txt` files.
2. Implement **token quota limitations** for LLM search.
3. Choose between:
   - `POST` method â†’ More secure for API calls
   - `GET` method â†’ Simpler but exposes data in URL

---

## **2025.03.02 (Sunday) - Heroku Deployment Failed**
### **(1) Tips for Deploying on Heroku**
#### **Slug Size Limitation**
- Maximum 500MB for all uploaded files.
- Ensure dependencies do not exceed this limit.

#### **Required Files**
- `Procfile` (e.g., `web:gunicorn app:app`)
  ```plaintext
  Ensure the filename is "Procfile" (no extension)
  Format: 'web: <command>' (e.g., 'web: gunicorn app:app')
- `.gitignore`
  ```plaintext
  venv/
  __pycache__/
  .env
  *.pyc
  *.pkl
  *.sqlite3
- `requirements.txt`
  ```python
  from sentence_transformers import SentenceTransformer
  model = SentenceTransformer('all-MiniLM-L6-v2')
-API KEY Setting
  ```bash
  heroku config:set OPENAI_API_KEY="YOUR_API_KEY"

### **(2) Reinitializing Heroku Apps**
#### **Must delete all git history:**
  ```bash
  git add .
  git commit -m "Initial Commit"
  git push heroku main

---

## **2025.03.09 (Sunday) - Render Deployment Success**
### **(1) Key Considerations for Render**
### **Memory Management**
- Frequent deployments may cause "Out of Memory" issues.
- Instead of "Clear Cache and Deploy", use "Deploy from Last Commit".
### **Important Environment Variables**
- OPENAI_API_KEY
- Vector_DATABASE_PATH
- ORIGIN_RAG_PATH
- HUGGINGFACE_TOKEN
### **Gunicorn Start Command**
  ```bash
  gunicorn --workers=1 --threads=2 --timeout=600 -b 0.0.0.0:$PORT app:app
### **(2) Handling Vector Search & API History**
### **Need to create FAISS index for vector-text mapping**
### **Convert JSON responses back to UTF-8 encoding for /api/check_history**

---

ðŸ”‘ Key Takeaways
1. User authentication is best handled via Flask session.
2. Vector database (FAISS) needs pre-built indexes for efficiency.
3. Deployment trade-offs:
- Heroku: Free tier has strict limitations (500MB slug size).
- Render: More stable, but needs instance upgrades for large memory usage.
4. Optimizing API requests:
- Avoid large token outputs to prevent rate-limit errors.
- Properly format API responses (UTF-8 encoding).

This project was a great learning experience in Flask, FAISS vector search, Render deployment, and LLM integration. ðŸš€ðŸ”¥